{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing CNN filters\n",
    "\n",
    "> Scale the weights between 0 - 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the distribution\n",
    "\n",
    "> 1) Take the features from the required layer and reduce it to 2 dimensions with **PCA** or **t-SNE**(t-distriubuted statistical neighbourhood embedding) (preferred)\n",
    "\n",
    "> 2) Plot the reduced feature for all data samples.\n",
    "\n",
    "> Here is a plot of t-SNE reduced feature points from ALEXNET with their corresponding image embedded. You can find similar images clustered together.\n",
    "\n",
    "<img src=\"files/tsne.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency maps\n",
    "\n",
    "Helps to find out the image pixels that mattered for classification\n",
    "\n",
    "> Find the gradient of the model output (say classification score) with respect to image pixels.\n",
    "\n",
    ">$\n",
    "\\text{SaliencyMap}[i,j] = \\frac{f(I) - f(I')}{I[i,j]-c}\n",
    "$\n",
    "\n",
    "> Where\n",
    "\n",
    ">>$\n",
    "I' \\quad \\text{is the image with pixel (i,j) set to some constant c}\\\\\n",
    "f \\quad \\text{is the model}\n",
    "$\n",
    "\n",
    "<img src=\"files/saliency.png\" width=600px />\n",
    "\n",
    "> Instead of the final score, **we can also find the gradient of some intermediate activations** (i.e, choose a specifc value in some CNN layer output). This will **show the patch of the image this neuron is looking at**.\n",
    "\n",
    "> Saliency maps can also be used for **Coarse Semantic segmentation** without needing any masked training data. However, the **model should be run repeatedly for every pixel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating synthetic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1) Define a **function that maximizes a particular class score** from model output (for **maximizing a function use gradient ascent update**)\n",
    "\n",
    ">>$\n",
    "max \\quad  S_c[I] - \\lambda ||I||_2^2 \n",
    "$\n",
    "\n",
    "> 2) Compute the **gradient of this lodd w.r.t image pixels**\n",
    "\n",
    ">>$\n",
    "I_t = I_t + \\gamma \\frac{\\partial (S_c[I] - \\lambda ||I||_2^2)}{\\partial I}\n",
    "$\n",
    "\n",
    "> 3) Update the image\n",
    "\n",
    "<img src=\"files/generate_image.png\" width=600px/>\n",
    "\n",
    "<img src=\"files/gen_image2.png\" width=600px/>\n",
    "\n",
    "<img src=\"files/gen_image3.png\" width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of maximizing a specific class score, **maximize L2 norm of an entire CNN layer output** and update the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/deepdream.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature inversion for image reconstruction\n",
    "\n",
    "<img src=\"files/feat_inv.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful for **image reconstruction**. The image image can be encoded as a feature vector, which can be used to decode the image\n",
    "\n",
    "The feature vectors in the earlier layers of CNN reconstruct images almost similar to original image\n",
    "\n",
    "<img src=\"files/reconstruct.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture synthesis (Gram reconstruction)\n",
    "\n",
    "Instead of matching a single feature vector, we try to consider **all features** by consolidating them in a **gram matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Let $F^l$ be the **feature tensor** from layer **l** of the image for which we want to generate texture \n",
    "\n",
    ">>$\n",
    "F_l \\in \\mathbb{R}^{C_l \\times H_l \\times W_l}\n",
    "$\n",
    "\n",
    ">Reshape the feature to a matrix\n",
    "\n",
    ">>$\n",
    "F_l \\in \\mathbb{R}^{C_l \\times H_lW_l}\n",
    "$\n",
    "\n",
    ">**Gram matrix** at layer **l** by computing the **outer product** of the **feature matrix**\n",
    "\n",
    ">>$\n",
    "G_l = F_lF_l^T \\in \\mathbb{R}^{C \\times C}\n",
    "$\n",
    "\n",
    ">Define the **loss function for texture synthesis**\n",
    "\n",
    ">>$\n",
    "E_l[I] = ||G_l - G_l'[I]||_2^2\\\\\n",
    "min \\quad L[I] = \\sum_l w_l E_l[I]\n",
    "$\n",
    "\n",
    ">Compute **gradient of loss function w.r.t image pixels and update image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending two images by applying **feature inversion** + **gram reconstruction**\n",
    "\n",
    "Do a **weighted minimization** of the following losses\n",
    "\n",
    "> Minimize **feature inversion loss** from **content image**\n",
    "\n",
    "> Minimize **Gram reconstruction loss** from **style image**\n",
    "\n",
    "<img src=\"files/style_trans.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss network** is a pre-trained network like **VGG**. We can train a separate feed forward network for each style\n",
    "\n",
    "<img src=\"files/style_trans1.png\" width=600px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
